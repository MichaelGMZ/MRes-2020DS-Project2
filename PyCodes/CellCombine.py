# %%
'''----------------------------------------------------------------
This script takes the cell info identified by fastER and Mask-RCNN
Then identify the difference between two methods in terms of # of objects
We have 7 parameters for now:
circumference | intensity | smooth | volume | centre | contour | instances
Each contains two experiment results: before | after
dict_bm, dict_am, dict_bf, dict_af
----------------------------------------------------------------'''
import os
import matplotlib.pyplot as plt
plt.style.use('ggplot')
import seaborn as sns
import numpy as np
import scipy.stats as stats
from CellOperation import Seg_Grey_Path
from tqdm import tqdm
import cv2
from scipy import stats
import matplotlib.gridspec as gridspec
import pickle
from skimage.io import imread, imshow, imsave

# %%
'''----------------------------------------------------------------
Intermediate function. Pass relevant parameters to pipeline
----------------------------------------------------------------'''
def Combine_Frame(par_path, save_plots):
    combine_path = os.path.join(par_path, 'combine')
    if not os.path.exists(combine_path):
        os.mkdir(combine_path)
    print ('Parent folder: {}'.format(par_path))
    print (f'--- Combine folder created ---\n')

    # if '160' in par_path:
    Pipeline(discrepancy_b, par_path, combine_path, dict_bf, dict_bm, save_plots = save_plots)
    # if '400' in par_path:
    # Pipeline(discrepancy_a, par_path, combine_path, dict_af, dict_am, save_plots = save_plots)

# %%
'''----------------------------------------------------------------
Identify different results generated by two algorithms
Baseline is Mask-RCNN
----------------------------------------------------------------'''
def Pipeline(discrepancy, par_path, combine_path, dict_f, dict_m, save_plots = False):
    '''
    Output: A new frame & Dictionary datatype discrepancy'''
    # for each frame of MRCNN as baseline, index is frame number
    for frame in tqdm(os.listdir(os.path.join(par_path, 'mrcnn'))):
        if frame.endswith('.png'):
            index = int(frame[6:9])
            img = imread(os.path.join(par_path, 'mrcnn', frame))
            img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
            
            # start & end are the indications of the start and end point of each frame
            # since all frames are stored together of which contains corresponding data
            if index == 1:
                start_m, end_m = 0, dict_m['instances'][0]
                start_f, end_f = 0, dict_f['instances'][0]
            else:
                start_m, end_m = dict_m['instances'][index - 2], dict_m['instances'][index - 1]
                start_f, end_f = dict_f['instances'][index - 2], dict_f['instances'][index - 1]

            # centroid of each detected cells are available (fastER & MRCNN)
            count = 0
            total = 0
            for n, centroid_f in enumerate(dict_f['centre'][start_f:end_f]):
                # if fastER centroid fall into MRCNN contours: pass
                check = False
                for m, contour_m in enumerate(dict_m['contour'][start_m:end_m]):
                    if cv2.pointPolygonTest(contour_m, centroid_f, False) > 0:
                        break

                    if cv2.pointPolygonTest(dict_f['contour'][start_f + n], dict_m['centre'][start_m + m], False) > 0:
                        break

                    if m == end_m - start_m - 1:
                        check = True

                # if not, check if fasetER contour fits the intensity, smoothness of MRCNN calculated earlier (e.g. 95% CI)
                if check:
                    total = total + 1
                    inten_f = dict_f['intensity'][start_f + n]
                    smoot_f = dict_f['smooth'][start_f + n]
                    conto_f = dict_f['contour'][start_f + n]
                    volum_f = dict_f['volume'][start_f + n]
                    inten_m = dict_m['intensity'][start_m:end_m]
                    smoot_m = dict_m['smooth'][start_m:end_m]
                    volum_m = dict_m['volume'][start_m:end_m]

                    # inten_interval = stats.t.interval(0.95, len(inten_m) - 1, loc = np.mean(inten_m), scale = stats.sem(inten_m))
                    # smoot_interval = stats.t.interval(0.95, len(smoot_m) - 1, loc = np.mean(smoot_m), scale = stats.sem(smoot_m))

                    # if inten_f >= inten_interval[0] and inten_f <= inten_interval[1]:
                    #     if smoot_f >= smoot_interval[0] and smoot_f <= smoot_interval[1]:
                    
                    # add fastER contour onto the MRCNN frame
                    if inten_f > np.percentile(dict_f['intensity'][start_f:end_f], 1):
                        # if volum_f < np.percentile(volum_m, 99):
                            if smoot_f < np.percentile(dict_f['smooth'][start_f:end_f], 99):
                                count = count + 1
                                contour_f = dict_f['contour'][start_f + n]
                                img = cv2.drawContours(img, contour_f, -1, (255, 255, 255), 1)

                                # add info of fastER contour to discrepancy dictionary thus can be referred 
                                # discrepancy = {} -> frame index -> dicts with 6 keys
                                if str(index) not in discrepancy.keys():
                                    discrepancy[str(index)] = {'volume':[], 'intensity':[], 'circumference':[], 'smooth':[], 
                                                                'contour':[], 'centre':[]}
                                        
                                discrepancy[str(index)]['volume'].append(dict_f['volume'][start_f + n])
                                discrepancy[str(index)]['intensity'].append(inten_f)
                                discrepancy[str(index)]['circumference'].append(dict_f['circumference'][start_f + n])
                                discrepancy[str(index)]['smooth'].append(smoot_f)
                                discrepancy[str(index)]['contour'].append(contour_f)
                                discrepancy[str(index)]['centre'].append(centroid_f)
            
            if str(index) in discrepancy.keys():
                discrepancy[str(index)]['instances'] = count
            
            if save_plots:
                plt.imsave(os.path.join(combine_path, str(frame)[:-4] + '.png'), img, format = 'png', dpi = 300)
                plt.imsave(os.path.join(combine_path, str(frame)[:-4] + '.svg'), img, format = 'svg')

# %%
'''----------------------------------------------------------------
Main part of the module goes here
----------------------------------------------------------------'''
if __name__ == '__main__':
    # PLOT_PATH = 'D:\Rotation2\Plots'
    VIDEO_PATH = 'D:\Rotation2\VideoFrame'
    # seg_folders, grey_folders = Seg_Grey_Path(VIDEO_PATH)

    PAR_PATH = 'D:\Rotation2\VideoFrame\extract_FTY720 spleen 1h both cells before.avi\YellowBlur'

    # dict_af = pickle.load(open(os.path.join(PAR_PATH, 'dict_af.pkl'), 'rb'))
    dict_bf = pickle.load(open(os.path.join(PAR_PATH, 'dict_bf.pkl'), 'rb'))
    # dict_am = pickle.load(open(os.path.join(PAR_PATH, 'dict_am.pkl'), 'rb'))
    dict_bm = pickle.load(open(os.path.join(PAR_PATH, 'dict_bm.pkl'), 'rb'))
    print ('--- Module imported & Data loaded successfully ---')

    discrepancy_b = {}
    discrepancy_a = {}

    # for folder in seg_folders:
    #     par_path = os.path.split(folder)[0]
    #     if 'Red' in folder:
    #         pass
    #     if 'Yellow' in folder:
    #         Combine_Frame(par_path, save_plots = True)
    Combine_Frame(PAR_PATH, save_plots = True)
    pickle.dump(discrepancy_b, open(os.path.join(PAR_PATH, 'discrepancy_b.pkl'), 'wb'))
    # pickle.dump(discrepancy_a, open(os.path.join(PAR_PATH, 'discrepancy_a.pkl'), 'wb'))
    print ('Session completed')